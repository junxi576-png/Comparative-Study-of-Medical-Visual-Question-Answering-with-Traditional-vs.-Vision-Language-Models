{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 197,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02542911633820725,
      "grad_norm": 10.014010429382324,
      "learning_rate": 0.00019864636209813877,
      "loss": 12.74,
      "step": 5
    },
    {
      "epoch": 0.0508582326764145,
      "grad_norm": 8.64881706237793,
      "learning_rate": 0.00019695431472081218,
      "loss": 8.0155,
      "step": 10
    },
    {
      "epoch": 0.07628734901462174,
      "grad_norm": 1.4331430196762085,
      "learning_rate": 0.00019526226734348562,
      "loss": 4.924,
      "step": 15
    },
    {
      "epoch": 0.101716465352829,
      "grad_norm": 0.6661530137062073,
      "learning_rate": 0.00019357021996615906,
      "loss": 4.4623,
      "step": 20
    },
    {
      "epoch": 0.12714558169103624,
      "grad_norm": 0.5092810392379761,
      "learning_rate": 0.0001918781725888325,
      "loss": 4.2832,
      "step": 25
    },
    {
      "epoch": 0.15257469802924348,
      "grad_norm": 0.2215346395969391,
      "learning_rate": 0.00019018612521150594,
      "loss": 4.1912,
      "step": 30
    },
    {
      "epoch": 0.17800381436745072,
      "grad_norm": 0.29600244760513306,
      "learning_rate": 0.00018849407783417936,
      "loss": 4.1328,
      "step": 35
    },
    {
      "epoch": 0.203432930705658,
      "grad_norm": 0.27767401933670044,
      "learning_rate": 0.0001868020304568528,
      "loss": 4.0631,
      "step": 40
    },
    {
      "epoch": 0.22886204704386523,
      "grad_norm": 0.2678418755531311,
      "learning_rate": 0.00018510998307952624,
      "loss": 3.9982,
      "step": 45
    },
    {
      "epoch": 0.25429116338207247,
      "grad_norm": 0.22603389620780945,
      "learning_rate": 0.00018341793570219968,
      "loss": 3.939,
      "step": 50
    },
    {
      "epoch": 0.27972027972027974,
      "grad_norm": 0.17454132437705994,
      "learning_rate": 0.0001817258883248731,
      "loss": 3.8878,
      "step": 55
    },
    {
      "epoch": 0.30514939605848695,
      "grad_norm": 0.23212780058383942,
      "learning_rate": 0.00018003384094754653,
      "loss": 3.8501,
      "step": 60
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 0.26888999342918396,
      "learning_rate": 0.00017834179357021997,
      "loss": 3.8254,
      "step": 65
    },
    {
      "epoch": 0.35600762873490144,
      "grad_norm": 0.3695148229598999,
      "learning_rate": 0.0001766497461928934,
      "loss": 3.8125,
      "step": 70
    },
    {
      "epoch": 0.3814367450731087,
      "grad_norm": 0.1405540406703949,
      "learning_rate": 0.00017495769881556685,
      "loss": 3.7988,
      "step": 75
    },
    {
      "epoch": 0.406865861411316,
      "grad_norm": 0.16706888377666473,
      "learning_rate": 0.00017326565143824027,
      "loss": 3.7829,
      "step": 80
    },
    {
      "epoch": 0.4322949777495232,
      "grad_norm": 0.1048629954457283,
      "learning_rate": 0.0001715736040609137,
      "loss": 3.7787,
      "step": 85
    },
    {
      "epoch": 0.45772409408773046,
      "grad_norm": 0.17084570229053497,
      "learning_rate": 0.00016988155668358715,
      "loss": 3.7735,
      "step": 90
    },
    {
      "epoch": 0.4831532104259377,
      "grad_norm": 0.189347043633461,
      "learning_rate": 0.0001681895093062606,
      "loss": 3.7652,
      "step": 95
    },
    {
      "epoch": 0.5085823267641449,
      "grad_norm": 0.15642620623111725,
      "learning_rate": 0.00016649746192893403,
      "loss": 3.7596,
      "step": 100
    },
    {
      "epoch": 0.5340114431023522,
      "grad_norm": 0.26023373007774353,
      "learning_rate": 0.00016480541455160744,
      "loss": 3.7673,
      "step": 105
    },
    {
      "epoch": 0.5594405594405595,
      "grad_norm": 0.3786662817001343,
      "learning_rate": 0.00016311336717428088,
      "loss": 3.7626,
      "step": 110
    },
    {
      "epoch": 0.5848696757787667,
      "grad_norm": 0.11224820464849472,
      "learning_rate": 0.00016142131979695432,
      "loss": 3.759,
      "step": 115
    },
    {
      "epoch": 0.6102987921169739,
      "grad_norm": 0.1926216334104538,
      "learning_rate": 0.00015972927241962776,
      "loss": 3.7557,
      "step": 120
    },
    {
      "epoch": 0.6357279084551812,
      "grad_norm": 0.08838542550802231,
      "learning_rate": 0.00015803722504230118,
      "loss": 3.7552,
      "step": 125
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.11044508963823318,
      "learning_rate": 0.00015634517766497462,
      "loss": 3.7526,
      "step": 130
    },
    {
      "epoch": 0.6865861411315957,
      "grad_norm": 0.1150602474808693,
      "learning_rate": 0.00015465313028764806,
      "loss": 3.7538,
      "step": 135
    },
    {
      "epoch": 0.7120152574698029,
      "grad_norm": 0.08761288970708847,
      "learning_rate": 0.0001529610829103215,
      "loss": 3.7564,
      "step": 140
    },
    {
      "epoch": 0.7374443738080102,
      "grad_norm": 0.10867762565612793,
      "learning_rate": 0.00015126903553299494,
      "loss": 3.7509,
      "step": 145
    },
    {
      "epoch": 0.7628734901462174,
      "grad_norm": 0.18101619184017181,
      "learning_rate": 0.00014957698815566835,
      "loss": 3.7558,
      "step": 150
    },
    {
      "epoch": 0.7883026064844246,
      "grad_norm": 0.13764391839504242,
      "learning_rate": 0.0001478849407783418,
      "loss": 3.7511,
      "step": 155
    },
    {
      "epoch": 0.813731722822632,
      "grad_norm": 0.2041599005460739,
      "learning_rate": 0.00014619289340101523,
      "loss": 3.7515,
      "step": 160
    },
    {
      "epoch": 0.8391608391608392,
      "grad_norm": 0.10715719312429428,
      "learning_rate": 0.00014450084602368868,
      "loss": 3.747,
      "step": 165
    },
    {
      "epoch": 0.8645899554990464,
      "grad_norm": 0.09191086888313293,
      "learning_rate": 0.0001428087986463621,
      "loss": 3.7525,
      "step": 170
    },
    {
      "epoch": 0.8900190718372537,
      "grad_norm": 0.12299282848834991,
      "learning_rate": 0.00014111675126903553,
      "loss": 3.7463,
      "step": 175
    },
    {
      "epoch": 0.9154481881754609,
      "grad_norm": 0.10152900218963623,
      "learning_rate": 0.000139424703891709,
      "loss": 3.7544,
      "step": 180
    },
    {
      "epoch": 0.9408773045136681,
      "grad_norm": 0.10348465293645859,
      "learning_rate": 0.0001377326565143824,
      "loss": 3.7493,
      "step": 185
    },
    {
      "epoch": 0.9663064208518753,
      "grad_norm": 0.09588255733251572,
      "learning_rate": 0.00013604060913705585,
      "loss": 3.7496,
      "step": 190
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.12192687392234802,
      "learning_rate": 0.00013434856175972926,
      "loss": 3.7489,
      "step": 195
    }
  ],
  "logging_steps": 5,
  "max_steps": 591,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.92820893139456e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
